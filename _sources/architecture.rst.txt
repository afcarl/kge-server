.. _architecture:


Service Architecture
====================

The service has an architecture based in docker containers. Currently it uses
three different containers:


- **Web container**: This container exposes the only open port of all system.
  Provides a web server (*gunicorn*) that accepts HTTP requests to the REST API
  and responds to them

- **celery**: This container is running on the background waiting for a task on
  its queue. It contains all library code and celery.

- **Redis container**: The redis key-value storage is a dependency from Celery.
  It also stores all the progress of the tasks running on Celery queue.


Server deployment v2
--------------------

The old version of this repository didn't had any Dockerfile or image available
to run the code. This has changed, and two containers has been created to hold
both web server and asyncronous task daemon (celery).

Also, a simple container orchestation with docker-compose has been used. You can
see all the information inside images/ folder. It contains two Dockerfiles and
a docker-compose.yml that allows to build instantly the two images and connect
the containers. To run them you only have to clone the entire repository and
execute those commands:

.. sourcecode:: bash

    cd images/
    docker-compose build
    docker-compose up

The previous method is still available if you can't use docker-compose on your
machine

Images used
```````````
The previous image used on developement environment was ``recognai/jupyter-scipy-kge``.
This image contains a lot of code that the library and rest service does not use.

Using ``continuumio/miniconda3`` docker image as base, it is possible to install
only the required packages, minimizing the overall size of the container.

Both containers will launch a script on startup that will reinstall the kge-server
package on python path, to get latest developement version running, and then
will launch the service itself: gunicorn or celery worker.

Standalone containers to use in production are not still available.

Server Deployment (deprecated)
------------------------------

**NOTE**: It is highly recommended to use the new server deployment method using
docker compose. The images generated are smaller and faster to build.

To configure the service we will need to install docker in our machine. After
that we will start pulling containers or creating images, so you need a good
internet connection and at least ~6 GB of free disk space

Getting all needed images
`````````````````````````
We need first to create the image for the service container. Until the container
is uploaded somewhere you can download it, you can use the following Dockerfile.
Copy it into a new folder and call it ``Dockerfile``

::

    FROM jupyter/scipy-notebook

    MAINTAINER Víctor Fernández <vfrico@gmail.com>

    USER root

    # install scikit-kge from github
    RUN git clone https://github.com/vfrico/kge-server.git
    RUN pip3 install requests --upgrade
    RUN pip3 install setuptools
    RUN pip3 install nose
    RUN cd kge-server/ && python3 setup.py install
    RUN rm -rf kge-server/
    RUN apt-get update && apt-get install -y redis-server
    RUN service redis-server stop


Now to build the image, change to the directory where you saved your Dockerfile
and execute the following command. You can tweak the :v1 version to whatever you
want.

::

    docker build -t kgeservice:v1 .


The second image we need to use is Redis. Fortunately the public docker registry
already has this image, so we will use it:

::

    docker pull redis


Once we have all needed images we need to run them

Running the environment
```````````````````````

The redis container acts like a dependency for our service container, so we
will launch it before. With the following command we start running a container
called ``myredis``.

::

    docker run --name myredis -d redis

After this, we will run the service container. This container still has several
packages installed on it, like jupyter notebook. It has many parameters you can
tweak as you want.

::

    docker run -d -p 14397:8888 -p 6789:8000 -e PASSWORD="password"\
    --link myredis:redis --name serviciokge\
    -v $PWD/kge-server:/home/jovyan/work\
    kgeservice:v1

If everythin went ok, we can see all running containers. We must see at least our
two containers, called ``myredis`` and ``serviciokge``

::

    docker ps

Now we enter into our container:

::

    docker exec -it serviciokge /bin/bash

and we have to run `~/work/rest-service/servicestart.sh` to run gunicorn and
`~/work/rest-service/celerystart.sh` to run celery.

After this you will be able to access the http rest service through the port :6789
