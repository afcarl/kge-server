{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urlRequest = \"\"\"https://query.wikidata.org/bigdata/namespace/wdq/sparql?query=\n",
    "PREFIX wikibase: <http://wikiba.se/ontology>\n",
    "SELECT ?bne ?wikidata \n",
    "WHERE { ?wikidata wdt:P950 ?bne .\n",
    "}\n",
    "LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "headers = {\"Accept\" : \"application/json\"}\n",
    "response = requests.get(urlRequest, headers=headers)\n",
    "\n",
    "\n",
    "map_bne_wkdt = [(item['bne']['value'],item['wikidata']['value']) for item in response.json()['results']['bindings']]\n",
    "# Resultado deseado (BNE-ID, Wikidata-Entity-URI)\n",
    "\n",
    "\n",
    "entities = []\n",
    "relations = []\n",
    "subs = []\n",
    "\n",
    "def add_element(element, complete_list):\n",
    "    try:\n",
    "        #Item is on the list -> you don't need to add again\n",
    "        return complete_list.index(element)\n",
    "    except ValueError:\n",
    "        # Item is not on the list -> add it and return id\n",
    "        complete_list.append(element)\n",
    "        return len(complete_list)-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "import dataset\n",
    "importlib.reload(dataset)\n",
    "\n",
    "\n",
    "da = dataset.Dataset()\n",
    "da.load_from_binary(\"aquimismo\")\n",
    "da.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"PREFIX wikibase: <http://wikiba.se/ontology>\n",
    "construct { ?wikidata ?predicate ?object . ?object ?predicate2 ?object2 . ?object2 ?predicate3 ?object3 }\n",
    "WHERE { ?wikidata wdt:P950 ?bne .\n",
    "?wikidata ?predicate ?object .\n",
    "?object ?predicate2 ?object2 .\n",
    "?object2 ?predicate3 ?object3\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def build_n_levels_query(n_levels):\n",
    "    def build_levels(n_levels):\n",
    "    ob1 = \"wikidata\"\n",
    "    pre = \"predicate\"\n",
    "    ob2 = \"object\"\n",
    "    pre_base = pre\n",
    "    obj_base = ob2\n",
    "    predicateCount = 1\n",
    "    objectCount = 1\n",
    "    \n",
    "    tripletas = []\n",
    "    \n",
    "    for level in range(1,n_levels+1):\n",
    "        tripletas.append((ob1, pre, ob2))\n",
    "        objectCount += 1\n",
    "        predicateCount += 1\n",
    "        ob1 = ob2\n",
    "        ob2 = obj_base + str(objectCount)\n",
    "        pre = pre_base + str(predicateCount)\n",
    "    \n",
    "    return tripletas\n",
    "\n",
    "\n",
    "lines = []\n",
    "for level in build_levels(4):\n",
    "    lines.append(\"?\"+level[0]+\" ?\"+level[0]+\" ?\"+level[2])\n",
    "    \n",
    "query = \"\"\"PREFIX wikibase: <http://wikiba.se/ontology>\n",
    "construct {{ {0} }}\n",
    "WHERE {{ ?wikidata wdt:P950 ?bne .\n",
    "{1}\n",
    "}} \"\"\".format(\" . \".join(lines), \" . \\n\".join(lines))\n",
    "\n",
    "print(query)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict1 = {\"a\":1, \"b\":2, \"c\":3, \"d\":4}\n",
    "print(dict1[\"b\"])\n",
    "print(len(dict1))\n",
    "dict1[\"e\"]=5\n",
    "len(dict1)\n",
    "l = [[3,4,5],[3,2,5],[3,5,5]]\n",
    "[tuple(x) for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "t.index(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "import dataset\n",
    "import model\n",
    "import skge\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(model)\n",
    "\n",
    "\n",
    "datos = dataset.Dataset()\n",
    "datos.load_from_binary(\"holographic-embeddings/data/wikidata_2.bin\")\n",
    "datos.show(verbose=False)\n",
    "\n",
    "tr = model.AutoModel(datos)\n",
    "model = tr.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open(\"holographic-embeddings/modeloentrenado\", 'rb')\n",
    "t = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict as ddict\n",
    "idx = ddict(list)\n",
    "tt = ddict(lambda: {'ss': ddict(list), 'os': ddict(list)})\n",
    "xs = [(1,2,3),(3,2,5),(1,2,4),(4,6,3)]\n",
    "for s, p, o in xs:\n",
    "    idx[p].append((s,o))\n",
    "\n",
    "for s, p, o in xs:\n",
    "    tt[p]['os'][s].append(o)\n",
    "    tt[p]['ss'][o].append(s)\n",
    "    \n",
    "print(dict(tt))\n",
    "# print(idx)\n",
    "print(dict(idx).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [(\"a\",[(0.026937118701835055, 50), (0.026937118701835055, 50)]), (\"b\",[(0.00099489368693191972, 50), (0.00099489368693191972, 50)])]\n",
    "sorted(l, key=lambda t: t[1][0], reverse=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "import dataset\n",
    "import algorithm\n",
    "import experiment\n",
    "import skge\n",
    "importlib.reload(experiment)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(algorithm)\n",
    "\n",
    "\n",
    "dtset = dataset.Dataset()\n",
    "# dataset.load_from_binary(\"holographic-embeddings/data/wn18.bin\")\n",
    "dtset.load_from_binary(\"wdata_15k.bin\")\n",
    "\n",
    "alg = algorithm.Algorithm(dtset)\n",
    "all_models = alg.find_best(ncomps=range(80, 100, 20),model_types=[skge.TransE])\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importlib.reload(algorithm)\n",
    "\n",
    "# print(all_models[1][0].get_conf())\n",
    "all_models[2].run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
