{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holographic embeddings data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset uses pickle to store and save on disk. When loaded from python, it comes a dictionary structure wich has 5 different entries:\n",
    "\n",
    "* `entities`\n",
    "* `relations`\n",
    "* And three different subsets\n",
    "    * `test_subs`\n",
    "    * `valid_subs`\n",
    "    * `train_subs`\n",
    "\n",
    "The **`entities`** and **`relations`** list contains simply identifiers. The three different subsets contains the relations between `entities` and `relations`, divided in `train_subs`, which is the biggest subset, `test_subs` and `valid_subs`. The structure of this subset is the same: [(`<id_entity>`, `<id_entity>`, `<id_relation>`), ...]. The id's are exactly the position they occupy on the entity and relations array, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('train_subs', 7997), ('relations', 930), ('entities', 8363), ('valid_subs', 1000), ('test_subs', 999)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"/home/jovyan/holographic-embeddings/data/wn18.bin\", 'rb') as fin:\n",
    "    data = pickle.load(fin)\n",
    "print ([(k, len(data[k])) for k in data.keys()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As an example, we can see below the internal structure of `valid_subs`. Is a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7224, 456, 243),\n",
       " (3710, 128, 38),\n",
       " (1760, 227, 109),\n",
       " (4747, 1097, 265),\n",
       " (1500, 245, 332),\n",
       " (2846, 147, 37),\n",
       " (1710, 245, 359),\n",
       " (3579, 226, 261),\n",
       " (5937, 802, 261),\n",
       " (7911, 806, 382)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tupla for tupla in data['valid_subs'][0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset python class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main target is having a Dataset class which can be filled with external data, and this object can be saved on disk with the same structure used on https://github.com/mnick/holographic-embeddings to train a network.\n",
    "\n",
    "Right now, the class has several methods:\n",
    "* `load_dataset_from_json`\n",
    "* `load_dataset_from_query`\n",
    "* `load_dataset_from_nlevels`\n",
    "* `load_entire_dataset`\n",
    "* `save_to_binary`\n",
    "* `load_from_binary`\n",
    "* `train_split`\n",
    "* `show`\n",
    "* And other private methods.\n",
    "\n",
    "On the `load_entire_dataset` method. It is necessary to generate internally a count query in order to know how many tuples should be retrieved from server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Taking a dict as key, value storage is much faster than try to save long strings in arrays. \n",
    "Also, the search is faster on a dict than in a list. The search is even faster when shorter is the string\n",
    "used as key in dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_ = {}\n",
    "di2 = {}\n",
    "di = {\"http://www.wikidata.org/prop/direct/P/prop/direct/P/prop/direct/P/a\": 4,\n",
    "      \"http://www.wikidata.org/prop/direct/P/prop/direct/P/prop/direct/P/b\": 3}\n",
    "\n",
    "st = \"P{0}\"\n",
    "strin = \"http://www.wikidata.org/prop/direct/P{0}\"\n",
    "\n",
    "\n",
    "for i in range(0, 1000000):\n",
    "    s = strin.format(i)\n",
    "    dict_[s] = i\n",
    "    di2[st.format(i)] = i\n",
    "    \n",
    "lis = [strin.format(i) for i in range(0, 1000000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 38.21 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 106 ns per loop\n",
      "10000000 loops, best of 3: 119 ns per loop\n",
      "The slowest run took 13.65 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000000 loops, best of 3: 77.2 ns per loop\n",
      "10 loops, best of 3: 26.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit dict_[\"http://www.wikidata.org/prop/direct/P999994\"]\n",
    "%timeit di[\"http://www.wikidata.org/prop/direct/P/prop/direct/P/prop/direct/P/b\"]\n",
    "%timeit di2[\"P999994\"]\n",
    "%timeit lis.index(\"http://www.wikidata.org/prop/direct/P999994\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage for Algorithm class\n",
    "\n",
    "The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage for Server Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a SearchIndex. We can choose between create a new one from a trained model, or load from other already built.\n",
    "\n",
    "The Dataset Class is loaded because is useful to work with entities' strings and id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kgeserver.server as server\n",
    "import kgeserver.dataset as dataset\n",
    "import pickle\n",
    "\n",
    "si = server.SearchIndex()\n",
    "\n",
    "# tm = pickle.load(open(\"modeloentrenado100k.bin\", \"rb\"))\n",
    "# si.build_from_trained_model(tm, 1000)\n",
    "\n",
    "# si.save_to_binary(\"annoyIndex100k.bin\")\n",
    "si.load_from_file(\"annoyIndex100k.bin\", 120)\n",
    "\n",
    "dt = dataset.Dataset()\n",
    "dt.load_from_binary(\"100k.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the server class. Is as simple as instantiate a Server object with the searchIndex attribute.\n",
    "\n",
    "In the example, gets a similar entities vector from a given id, and shows the complete URI through screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[556]\t https://www.wikidata.org/wiki/Q37853\n",
      "[1701]\t https://www.wikidata.org/wiki/Q131808\n",
      "[1267]\t https://www.wikidata.org/wiki/Q288928\n",
      "[1536]\t https://www.wikidata.org/wiki/Q37068\n",
      "[1654]\t https://www.wikidata.org/wiki/Q748\n",
      "[1702]\t https://www.wikidata.org/wiki/Q1474884\n",
      "[28327]\t https://www.wikidata.org/wiki/Q624895\n",
      "[43197]\t https://www.wikidata.org/wiki/Q5098\n",
      "[1462]\t https://www.wikidata.org/wiki/Q19588\n",
      "[565]\t https://www.wikidata.org/wiki/Q11344\n"
     ]
    }
   ],
   "source": [
    "id1 = dt.get_entity_id(\"Q5682\")\n",
    "\n",
    "s = server.Server(si)\n",
    "similares = s.similarity_by_id(556,10)\n",
    "\n",
    "for ent in similares:\n",
    "    b_ent = \"https://www.wikidata.org/wiki/\"\n",
    "    print(\"[\"+str(ent)+\"]\\t \"+b_ent+dt.get_entity(ent))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
