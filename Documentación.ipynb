{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holographic embeddings data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset uses pickle to store and save on disk. When loaded from python, it comes a dictionary structure wich has 5 different entries:\n",
    "\n",
    "* `entities`\n",
    "* `relations`\n",
    "* And three different subsets\n",
    "    * `test_subs`\n",
    "    * `valid_subs`\n",
    "    * `train_subs`\n",
    "\n",
    "The **`entities`** and **`relations`** list contains simply identifiers. The three different subsets contains the relations between `entities` and `relations`, divided in `train_subs`, which is the biggest subset, `test_subs` and `valid_subs`. The structure of this subset is the same: [(`<id_entity>`, `<id_entity>`, `<id_relation>`), ...]. The id's are exactly the position they occupy on the entity and relations array, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('train_subs', 7997), ('relations', 930), ('entities', 8363), ('valid_subs', 1000), ('test_subs', 999)]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"/home/jovyan/holographic-embeddings/data/wn18.bin\", 'rb') as fin:\n",
    "    data = pickle.load(fin)\n",
    "print ([(k, len(data[k])) for k in data.keys()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As an example, we can see below the internal structure of `valid_subs`. Is a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7224, 456, 243),\n",
       " (3710, 128, 38),\n",
       " (1760, 227, 109),\n",
       " (4747, 1097, 265),\n",
       " (1500, 245, 332),\n",
       " (2846, 147, 37),\n",
       " (1710, 245, 359),\n",
       " (3579, 226, 261),\n",
       " (5937, 802, 261),\n",
       " (7911, 806, 382)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tupla for tupla in data['valid_subs'][0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset python class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main target is having a Dataset class which can be filled with external data, and this object can be saved on disk with the same structure used on https://github.com/mnick/holographic-embeddings to train a network.\n",
    "\n",
    "Right now, the class has several methods:\n",
    "* `load_dataset_from_json`\n",
    "* `load_dataset_from_query`\n",
    "* `load_dataset_from_nlevels`\n",
    "* `load_entire_dataset`\n",
    "* `save_to_binary`\n",
    "* `load_from_binary`\n",
    "* `train_split`\n",
    "* `show`\n",
    "* And other private methods.\n",
    "\n",
    "On the `load_entire_dataset` method. It is necessary to generate internally a count query in order to know how many tuples should be retrieved from server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docs for `scikit-kge` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Once trained the model (through a trainer), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
